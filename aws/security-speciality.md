# How IAM is used to securely manage access 
Identity and Access Management 
- Authorization: what can be accessed, once account is authenticated 
- access control: method of accessing secure resource 
- manage, control, govern authentication, authorization, and access control w/n AWS account 
## Features 
- on the dashboard, has sign-in link for users, and the ability to customize it
- resources
- best practices: AWS offers a list of best practices (doesn't show anything in govcloud)
- groups: assign policies to users. Not necessarily used to allow access in and of themselves 
- roles: operate similar to users, but designed to be assumed to identity or service to have access to temporary permissions 
- policies: written in JSON, defines what can and can't be accessed
    - assigned to users, groups, roles 
    - AWS managed policies 
    - customer managed policies 
        - inline policies 
- access management > account settings 
    - lists the password policy 
    - lists security token service endpoints 
        - recommended to disable the endpoints that aren't used 

# Managing User Identities with Long Term Credentials in IAM
## Overview of the User Dashboard 
- Users: objects representing an identity 
    - user overview
        - last activity 
            - green check: <90 days since last access 
            - orange triangle: 91-365 days since last access
            - red triangle: >365 days since last access
            - helps to ensure unused user accounts aren't hanging around 
        - path: location of user, especially for larger orgs with layers of user management 
        - mfa: listed if it's enabled
        - arn: unique identifier of the IAM user 
- secret keys: access key id, secret access key

# Managing Access using IAM User Groups & Roles 
## Manaing Multiple Users w IAM User Groups
- can't be directly referenced as a principal in a policy; allow access to users w/n group
- usually ment to align with teams and permissions the team needs, e.g., developers, admins 
    - avoids updating policies assigned directly to each user
- soft limit of 300 groups
- each user can only be added to 10 groups 
## IAM Roles
- allow trusted users, aws services, and applications to get temporary credentials to access resources 
- can be assumed by different identities when required 
- do not have long-term credentials (like password or access keys)
- uses trust relationship that defines who or what can use the role 
- assumption rules
    - user in same acct
    - user in diff acct
    - aws service
    - external federated user 
## Using AWS services roles to access AWS resources on your behalf
- service roles
    - commonly used on ec2 instances to use other resources 
    - role can be assigned at creation or while instance is running 
    - using roles is far superior to having access keys stored on the instance 
- service-linked roles 
    - often created first time a service is used
    - preconfigured by AWS to include the resources it needs access to
        - e.g. AWSServiceRoleForAmazonSSM
            - has AWS managed Policy configured, which cannot be accessed 
            - specifically designed to provide access to AWS SSM
## Using IAM User Roles to Grant Temporary Access for Users 
- when a role is assumed, it temporarily REPLACES all other permissions the user has 
- when creating a role, can use 'AWS account' within the current environment, rather than having to have a trust relationship w ec2; just use the account ID of the current account 
    - then add an inline policy to the user to assume that role
    - often used to allow cross-account, but works w/n account too
## Using Roles For Federated Access
- allows authentication from web identity or SAML 2.0 federation
    - web identity federation
        - federation: two provides have a level of trust where one party is the identity provider (IdP) and service provider (SP)
        - irl, like signing in with facebook/google/apple 
        - authentication token provided from IdP, and then the role is assumed and user able to be authenticated 
        - AWS Cognito best way to do it with mobile apps 
    - SAML 2.0: (security assertion markup language)
        - generally meant for authenticating employees, e.g. if using MS AD
        - minimizes amount of admin use & allows for single sign-on
        - can pick b/w programmatic access and programmatic and gui access 

# Using IAM Policies to Define and Manage Permissions 
## IAM AWS Policy Types
- identity-based policies
    - attached to users, groups, roles
    - managed
        - saved to policy library,
        - able to be attached to multiple entities 
        - aws-managed policies
        - customer-managed policies 
    - inline
        - embedded directly to entity; only exists w/n entity
        - can't easily be attached to other entities 
        - not usually best practice; requires additional administration effort
- resource-based policies
    - attached inline to resources (e.g. trust policy)
    - inline policies assigned to a resource instead of an entity, e.g. S3 bucket policy 
    - must have principal defined w/n the policy
- permission boundaries
    - can only be associated w role or user; define max level of perms that can be granted
    - act as guide-rail for max permissions allowed 
- organization service control policies (SCPs) (used by AWS organizations)
    - similar to permission boundaries, at account level
    - define boundary of max permissions
    - associated w aws account or account OU
    - does not allow access, only acts as a guide-rail
## Examining the JSON Policy Structure
- (JavaScript Object Notation)
- version: specifies policy language version & language syntax used
- statement: defines main elements of the policy
    - must contain at least one statement, or can contain an array of statements 
- sub-elements 
    - sid: set a unique identifier w/n statement 
    - effect: grant or reistrict access for the actions defined in the statement 
    - principal: defines which principal the policy relates to
        - not needed for identity-based policies
    - NotPrincipal
    - action: action that will either be allowed or denied, depending on value entered for 'effect'
        - based on the APIs & actions associated with the AWS services 
    - NotAction
    - resource: specifies actual resource action & effect to be applied to using ARNs
        - usually arn:partition:service:region:account-id:resource 
            - partition is aws or aws-us-gov
            - region left blank for services that are global
    - NotResource
    - condition (optional): control when permissions will be effective based upon set criteria 
## Policy Evaluation Logic 
- every request for permissions is evaluated through a list of steps 
    - authentication: ensure principal is authenticated as valid
    - context: what service or action is being requested
    - policy evaluation: determine level of access 
    - result: AWS determines if access is allowed or denied 
- policy evaluation
    - by default, all access denied
    - only allowed if an allow has been associated with a policy attached to a principal
    - if a deny is associated with the principal at any point, access denied
    - explicit deny will always take precedence over allow 
    - checks organizational SCPs, then resource-based policies, IAM permission boundaries, and finally identity-based policies 

# The Difference Between Authentication, Authorization, and Access Control in AWS 
## Authentication
- requires two parts of information
    - identification: unique value in aws account to authenticate to
        - can't have two of the same username in the same account 
    - verification: verify identity by providing password 
## Authorization
- takes place once an identity has been authenticated
- establishes what level access the authenticated entity has 
## Access Control
- logical access controls 
    - username/password authentication method
    - username/password method + MFA
    - basically, what access methods are required to access a resource 
    - use of roles or federation to provide permission
    - NACLs/SGs
    - related to authentication & authorization

# Authorization Controls in AWS 
## IAM
- best practice: attach policies to groups and add users to groups 
- customer-managed policies can help ensure least priviledge vs using AWS managed policies 
    - able to 'import managed policies' when creating a customer-managed policy to modify AWS managed policies and customize them
- can separate actions in policies with commas 
## S3
- IAM authorization
    - S3 Bucket Policies
        - only applied to buckets w/n s3; act as resource-based policies 
        - when applied, affects all objects in bucket 
        - ACL bucket policy principals - can be users, federated/IAM, aws acct or aws services
        - allow setting conditions w/n policy
            - e.g. restrict based on IP address 
    - S3 ACLs
        - able to set different permissions per object 
        - set at bucket or object level
        - conditional statements not supported
        - less granular than bucket policies 
        - able to add canonical ID of another account allowed to access bucket 
- permission conflicts are based on the principle of least privilege
    - if there is a single deny anywhere in the permissions, access is denied 
## NACLs
- authorize network traffic w/n vpc at protocol and subnet level
- can be applied to one or multiple subnets
- default NACL allows all traffic in/out
- NACL rules
    - rule number: acl rules are read in ascending order
        - sequence rules with organized numbering system and leave ~50 spots b/w each
    - type: select a protocol type from dropdown list
    - protocol: provides value for custom rules
    - port range: specify port range for protocol
    - source: define specific IPs or allow all 
    - allow/deny: what to do w traffic
- stateless; need an inbound rule to allow responses to outbound requests
## Security Groups 
- associated with instances, filter traffic into/out of instance
- NO DENY action for rules 
- stateful: don't need an inbound rule to allow traffic in 
- AWS SG rules fields
    - name: up to 255 characters
    - security group rule ID
    - ip version: 4/6
    - type
    - protocol: for custom rules
    - port range
    - source: sg, subnet, ip address allowed
    - description 

# AWS Authentication Mechanisms
## Username/Password & MFA
- usernames must be unique w/n the account
    - usernames verify identity
- password can technically be the same between every user
    - passwords provide verification of identity 
- username/password alone not considered very secure
- MFA: user must use second step of authentication after submitting password 
    - no extra charge to use this service
    - must be configured and associated with the user 
## Programmatic Authentication
- access via CLI, APIs, powershell, SDKs
- access keys composed of
    - access key ID: 20 random uppercase alphanumeric characters (A-Z, 0-9)
    - secret access key: 40 random upper/lowercase alphanumeric and non-alphanumeric characters 
- access keys can be created for any user that needs programmatic authentication 
- not possible to retrieve lost security keys 
- after creation, must be associated with system/application that will use them \
- rotating access keys decreases the possibility of the keys being compromised
    - process
        - create a second key
        - download new access keys
        - associate keys with application (e.g., aws configure to add new credentials)
        - mark existing access keys as inactive
            - test to make sure the new keys work
        - delete old keys 
- for instances (and probably in general) better to use roles 
## IAM Roles
- efficient & secure solution in authenticating & authorizing access 
- avoids embedded credentials w/n app 
- simply an object with a list of associated permissions 
- temporary access keys are provided when roles are assumed
- permissions from user and role are NOT amalgamated - the role TOTALLY takes over 
## Key Pairs
- made up of public and private keys
    - either ED25519 OR 2048-bit SSH-2 RSA
        - ED25519 doesn't work for instance connect or windows instances 
- on windows instances, decrypts the admin password
- on linux instances, enables ssh connection 
## Federation 
- allows users authenticated by external IdPs to access AWS 
- trust relationship b/w IdP and AWS account is established 
    - OpenID (e.g. facebook/google/apple login)
    - SAML 2.0 (e.g. MS AD)

# Using AWS Identity Federation to Simplify Access at Scale 
- identity federation: method where two identity providers can establish a level of trust 
    - identity provider (IdP) authenticates identity, and service provider gives authorization based on credentials 
    - often correlates with SSO
    - assertion: contains metadata and attributes about user such as username
        - sent from IdP after user authenticates their identity to the service provider 
        - allows service provider to grant access to their services 
- OAuth 2.0, ODIC (OpenID Connect), SAML 2.0 (Security Assertion Markup Language)
    - OIDC: simple identity layer on top of OAuth 2.0
- services offered by AWS
    - AWS SSO (now succeeded by IAM Identity Center)
        - allows creation of SSO approach to access multiple AWS accounts w/n AWS organization using a single IdP
    - AWS IAM
        - supports federated access via OpenID or SAML
    - Amazon Cognito 
        - simplify user access to mobile or web app using SAML or web identity federation 
        - able to scale to million so of users 
        - able to create a custom portal for users to see when signing in 

# AWS Incident Response: Isolating your EC2 instances 
- containment is a critical part of incident response 
- ought to have an incident response playbook before problems occur 
- isolation: limiting visibility of instance to itself and other instances
- detection mechanisms
    - Amazon GuardDuty: continuous monitoring of vpc flow logs and metadata
        - able to identify instances that are mining crypto or serving malicious traffic 
    - Amazon Inspector 
- how should one isolate EC2 instances 
    - SG isolation
        - easy to add SGs to instances & limit traffic
        - to keep in mind
            - have to explicitly allow traffic
                - most permissive security group rules WILL BE ALLOWED
            - CANNOT SHUT OFF TRAFFIC to an instance by adding an SG; would have to remove all the SGs before adding a blocking SG
                - since they are stateful, can allow traffic back in the network 
                - tracked vs untracked connections 
                    - untracked connections, e.g. 0.0.0.0/0, where all traffic/ports are allowed in/out
                        - when an SG is updated, e.g. rule added, removed, updated, or sg deleted, this traffic is interrupted
                    - tracked connection, e.g. allowing a specific port from a specific IP or CIDR rule
                        - traffic will not be immediately interrupted when SG is updated 
                        - still technically possible for a malicious user to be connected to the instance, with a tracked connection, the SG change to block all traffic in, and that user to remain connected. They wouldn't be able to reconnect, but they wouldn't be forced to disconnect 
                            - to remove tracked connections
                                - created dedicated 'isolation' SG
                                - create single rule of 0.0.0.0/0 for all traffic in both inbound & outbound rules
                                - remove any existing security groups attached to the instance 
                                - associate the isoluation SG to the instance 
                                - delete both inbound and outbound rules from the isolation SG
                                - result: converts all tracked connections into untracked connections & blocks everything 
    - NACL isolation 
        - all rules based on external IP addresses or CIDR blocks, can't block traffic w/n env
        - only one allowed per subnet 
        - very easy to stop inbound/outbound traffic
            - only need one rule per allow and deny to block all traffic 
        - can't be used in a targeted way 
        - how to
            - add deny all rule to inbound & outbound rules as the first rule 
    - Route Table Isolation
        - to disable access to outside, remove all routes in route table or create a new, empty route table
            - disables all external subnet communications, HOWEVER subnets would still be able to communicate w/n VPC
    - Internet Gateway Isolation 
        - can't be removed from VPC if there's any dependencies in the VPC 
            - requires turning off all instances 
        - only real option would be to remove routes to route table 

# AWS CloudTrail: An Introduction 
- used to track and audit all API calls in an account 
## What is AWS CloudTrail
- records & tracks all API requests in AWS account
- every API requestcaptured as an event
- multiple evens recorded w/n CT logs
- events contain array of associated metadata 
- new log files created every 5 minutes
    - delivered and stored w/n S3
    - can also be delivered to CloudWatch logs for metric monitoring & alerting w SNS
- CT Infrastructure 
    - global service
    - supports 60+ AWS services/features 
- use cases for captured data
    - effective for security analysis
        - monitor restircted api calls
    - resolve day-to-day operation issues 
    - track changes to AWS infrastructure (AWS Config helps with this as well)
    - CT logs can be used as evidence for compliance and governance controls (ISO, PCI DSS, FedRAMP)
## How AWS CloudTrail works
- Core features & services
    - trails: building blocks of the service
    - s3
    - logs: created by CT & capture events every 5 minutes & delivers to bucket 
    - kms: enable encryption
    - SNS: notify when different actions occur 
    - CW logs: deliver logs for metrics monitoring
    - event selectors: select what part of events to capture
    - tags
    - events: tracked in CT log file
    - API activity filters: events are stored in console for 7 days 
- CT process flow
    - create a trail (so CT knows which apis to track)
    - specify s3 bucket for log storage
    - optional: encrypt log files w kms
    - optional: sns notifications of new log files
    - optional: enable log file validation
    - trail created
    - post creation config
    - option: deliver CT to CW for monitoring
    - optional: configure event selectors
    - optional: add tags
    - configuration complete
    - after config, use API activity filter
- lifecycle of API call in CT
    - API call captured if it matches trail and stored in log file
    - sends to s3 or cw logs
    - in s3, stored in default s3 sse 
        - s3 lifecycle policies may apply 
## Understanding AWS CloudTrail Permissions
- Granting Access to CT
    - required proper permissions & authorization to use CT
    - create customer-managed or use AWS managed policies
        - AWS managed policies available are full access or read only access 
            - full-access also includes full access to sns and s3 
- s3 bucket policy 
    - specify bucket for CT logs
        - create new s3 bucket
            - CT configures and applies bucket policy w relevant permissions allowing logs to be delivered to bucket 
        - use existing s3 bucket
            - customer must configure and set up permissions
- CT & KMS
    - specific permisssions req'd to decrypt logs
    - adds another layer of encryption to CT logs files 
    - SSE-KMS can be chosen when creating trails
        - two options
            - create new KMS key (aws applies proper perms)
            - use existing keys (must create own policy; must be in same region as CT)
                - user will need decryption permissions 
## Understanding Trails
- w/o a trail, CT unable to capture API calls
- Trails hold all config information for capturing API calls 
## Insight into AWS CloudTrail Logs 
- what is a log file? 
    - written in JSON
    - new event written for each API call
    - new log file created every 5 minutes
    - log files delivered to s3 ~15 minutes after API call was initiated 
- events in a log file 
    - eventName: name of actual API that was called
    - eventSource: service which API call was made against 
    - eventTime
    - SourceIPAddress: of the requester who made API call
    - userAgent: method request was made through
        - signin.amazonaws.com (user in AWS console)
        - console.amazonaws.com (root user)
        - lambda.amazonaws.com 
    - userIdentity: set of attributes about identity that made request
- log file name convention
    - AccountID_CloudTrail_RegionName_YYYYMMDDTHHmmZ_UniqueString.FileNameFormat
        - time in utz
        - unique string is 16 digit alphanumeric character
        - default filename is json.gz 
- s3 bucket folder structure
    - BucketName/prefix/AWSLogs/AccountID/CloudTrail/RegionName/YYYY/MM/DD
        - prefix is optional to aid w organization
- multiple accounts and multiple logs 
    - CT logs from multiple accounts can be aggregated to same bucket
    - can't do the same w CW logs 
- log aggregation process
    - create new Trail in primary AWS acct
    - apply perms to S3 bucket allowing cross-acct access 
    - create new Trail in second AWS accts using Bucket name from primary AWS acct
        - AWS will give a warning; make sure to use the same name & prefix
    - create Trail & logs will be delivered to same S3 bucket in primary AWS acct 
- accessing cross-acct log files
    - if other accounts want read access, use roles in the primary aws acct and give users in other accounts ability to assume the roles
- log file integrity
    - verify log files have remained unchanged since CT delivered to S3 bucket
    - configured during Trail creation
- log file integrity process
    - hash created for log file by CT
    - CT creates new digest file every hour to verify logs have not changed
    - digest files contain detail of all logs delivered w/n last hour 
    - to verify the integrity, public key of log is used 
    - can only be done via CLI 
    - stored under different prefix than rest of CT logs 
## Montoring with AWS CloudTrail
- CloudWatch allows any event from CT to be monitored 
    - e.g. monitoring major changes in SGs, instance creation/stoppage/rebooting unexpectedly, changes to policies in s3 + IAM, monitoring failed login attempts to management console, API calls that result in failed authorization 
- CT + CW
    - to deliver logs to CW, Trail must be config'd to use CW
    - to deliver to CW, needs a role to be able to make CW logs logstream
- CW config
    - have a size limitation of 256KB
    - add metric filters to allow search of the logs 
    - each metric filter requires filter pattern
        - filter patterns determine what data CW is monitoring

# AWS Config: An Introduction 
- config: management tool service 
## What is AWS config
- Resource Management 
    - important to understand what resources are being used, any security vulnerabilities to worry about, how resources are linked w/n the environment, change history of resources, is infrastructure compliant with internal/external controls, is accurate audit info available 
- what can AWS config do
    - capture resource changes (within configuration items (CI))
    - act as resource inventory
    - store configuration history; able to save history of changes against a resource 
    - provide a snapshot of configurations (along with metadata)
    - notify about changes to resources
    - provides AWS CT integration 
    - use rules to check compliance 
    - perform security analysis w/n env 
    - identify relationships between resources 
- AWS Config & regions
    - regional service; must be configured per region 
    - able to also include global services 
## Key Components
- AWS Resources
    - typically classed as objects that can be created, updated, or deleted
    - config records state of resources in specific region
- Configuration Items
    - json file holds config and relationship information, among other info like metadata about a resource 
    - records CIs for directly related resources as well 
    - five sections
        - metadata: info about CI itself 
            - version & config ID
            - MD5Hash for comparision
            - time of capture and state ID
        - attributes: info about resource
            - unique resource ID
            - key-value tags
            - resource types 
            - ARN 
        - relationships
            - description of relationships to other resources 
        - current configuration
            - displays info from describe or list calls from AWS CLI
        - related events
            - displays related CT event ID
                - helps dive into 'who' 'what' and 'when'
    - used by configuration history, streams, and snapshots 
- Configuration Stream (CS)
    - when new CIs are created, sent to CS & sent to SNS
    - other events CS used for
        - configuration history files delivered
        - configuration snapshots started
        - state of compliance changes for a resource
        - evaluations begin 
        - when AWS Config fails to deliver notifications 
    - SNS can have different notification endpoints
        - email, SQS
            - can be spammy on email 
- Configuration History
    - uses CIs to produce a history of changes for a resource
    - able to see changes over time on a resources
    - able to view in console or CLI 
    - typically delivered every 6 hours to S3 
- Configuration Snapshot
    - takes point in time of all supported resources configured for that region & creates CIs for each resource 
- Configuration Recorder
    - responsible for recording all changes of resources and generating the CIs 
    - can be stopped/started
        - when stopped, doesn't track changes to resources 
- Config Rules
    - enforce specific compliance controls across resources
    - each rule is essentially a lambda function that looks at resources and checks compliance against rules. Sends a message to SNS & marks resource as non-compliance
        - non-compliant resources operate as normal, and it's up to user/admin to take the action
    - able to use predefined list of AWS Managed rules & able to define custom rules 
    - highly recommended for maintaining security checks & configurations 
    - when first enabled, it's likely to see a bunch of resources as noncompliant 
    - soft limit of 50 rules per region 
- Resource Relationships 
    - config identifies relationships b/w resources, e.g. which instances use what volumes 
- SNS Topic
    - used as configuration stream for notifications 
    - best practice is to programmatically analyize results in SQS before sending to SNS
- S3 bucket
    - used to store all Config History files and Snapshots 
- Permissions
    - IAM role is req'd to allow config to obtain the correct perms to interact w other services, e.g. reading resources, writing to S3 
- summary
    - configure the elements for the Configuration Recorder
    - AWS config discoveres all supported resources
    - for any change on a resource, a CI will be created and a notification is sent
    - AWS config checks current config rules to evaluate if the change is noncompliant
    - if a configuration snapshot is taken, AWS config will create a snapshot and delever to specified S3 bucket
    - after 6 hours, a configuration history file will be created 
- demonstration
    - able to send Configuration History reports to an S3 bucket in another account, and SNS notifications can go to a topic in another account 
## Service Integration
- integrates w SNS, SQS, S3, CloudTrail, IAM
    - SNS: used for configuration stream for CI
        - multiple accounts can subscribe to same topic in a primary AWS acct 
    - SQS: can subscribe to Configuration Streams for HA and decoupled apps + data extraction 
        - can perform custom filtering
        - can be subscribed to multiple Configuration Streams 
    - S3: used to store CI w/n single bucket
        - can contain configuration history and snapshots
    - AWS CloudTrail
        - integrates w config at CI level 
        - the CT data can be seen w/n config console on the event 
            - also stored in CT 
        - also tracks some APIs from AWS config 
    - IAM
        - role required to give permissions to service to publish data to SNS/S3 
        - config must be able to describe list and get API calls on resources it monitors 
## Managing Compliance with AWS Config
- compliance sources
    - come from different resources, e.g. HIPAA, internal security controls, internal standards
- config rules
    - manage and organize compliance for env
    - acts as automatic compliance checker 
    - AWS Managed Rules
        - cover a variety of best practices 
        - can be edited to match env requirements 
    - notifications are sent allowing appropriate actions to be taken
        - reesolve security issue
        - identify who/what made the change
- creating/modifying rules
    - identify compliance and standards
    - define requirements from all parties 
## AWS Config Use Cases 
- security compliance 
    - enforce strict compliance rules
    - notifications of noncompliance 
    - continually monitoring resources 
- discovery of resources
    - once started, config will discover all supported resources 
- audit compliance 
    - external governance controls: FERPA, HIPPA, PCI DSS, SOC
    - setting custom and managed rules to stay in compliance
    - able to prove history of changes
- resources change management
    - helpful to understand change of resources upon other resources 
- troubleshooting & problem management
    - using config dashboard, able to see timeline of events and go back before an incident happened and see what occured beforehand 

# Amazon Inspector 
## What is Amazon Inspector?
- helps identify security vulnerabilities w/n EC2 instances and apps 
- automatically achieved using assessments based on hundreds of best practices and known security weaknesses
    - common vulnerabilities and exposures (CVE)
    - center for internet security (CIS) benchmarks 
    - security best practices
    - runtime behavior analysis 
- when assessment complete, report is generated 
- service is agent based; requires software to be installed on instances that should be assessed 
- rule package customization
    - able to select which packages are best for use case
- why use it? 
    - security breaches on the increase
    - targeting small and large companies 
- security in the cloud
    - security is one of the top reasons why organizations are slow to adopt cloud tech
    - AWS invests a lot into security
- why use inspector'
    - increase confidence in level of security built into apps and services
    - confidence benefits orgs and customers
    - inspector cross-checks resources for security compliance, threats, and vulnerabilities, reducing exposure attacks 
## Components of Amazon Inspector
- amazon inspector role
    - required to create or select role to allow inspector to have read only access to all ec2 instances
- assessment targets
    - group of instances that assessment is run against 
    - uses tags to define groups of assessment targets 
        - only a match of one key is necessary in a list of multiples 
- aws agents
    - software agents installed on instances that are meant to be monitored
    - can track and monitor data across the network, along w file system and any process activity of instance
    - telementry data fed to inspector service over TLS
    - regular heartbeat sent from agent to inspector, which service will respond to w instructions
    - agent updates are managed & automatically installed by AWS 
- assessment templates
    - define specific configurations as to how an assessment is run on instances 
    - configurable items
        - rules packjaged to be used
        - duration of assessment: 15m/1h/8h/12h/24h. 1h recommended by AWS
        - SNS topics: can be configured to notify about an assessment run
        - inspector-specific attributes to be assigned to findings 
        - CANNOT be modified after creation
- rule packages
    - contains a number of individual rules that are each checked against instance metadata when assessment is run
    - each rule has an associate severity
        - high
            - should be rectified immediately 
            - would likely compromise the integrity, confidentiality, and availability of data 
        - medium
            - should be rectified in a timely manner
            - poses a risk to integrity, confidentiality, and availablility of data
        - low
            - log urgency on remediation, but still requires attention
        - informational
            - describes a particular security config w/n assessment target 
    - CVE
        - rules w/n package will check for exposures to known security holes that would compromise CIA of instance
        - aws updates this list w new CVEs when they're available
    - CIS
        - global standard for protecting data and resources 
        - AWS is a CIS benchmarks member company 
    - security best practices 
        - looks for weaknesses in common security best practices
        - can ONLY be run against assessment targets that are running Linux 
        - covers the following checks
            - disable root login over SSH
            - support SSH version 2
            - disable password auth over SSH
            - configure password maximum age/minimum length/complexity
            - enable ASLR
            - enable DEP
            - configure perms for system dirs (e.g. only root has access to / dir)
- Assessment Run
    - occurs once inspector role configured, agents installed, assessment target config'd, assessment template config'd
    - telemetry sent back to inspector and s3 to assess data against rules packages
    - multiple assessments can be run if they're not overlapping instances
- telemetry
    - data collected from instance, detailing config, behavior and processes during assessment run
    - once collected, sent to inspector in near-real-time & stored in s3
    - s3 data encrypted & deleted after 30 days
- assessment reports
    - provides details on what was assessed and the results of that assessment
    - findings report
        - contains subset of full report
        - summary of assessment
        - list of instances assessed
        - rules packages used
        - detailed report on findings that occured
    - full report
        - everything in finding report plus 
        - list of rules that were passed successfully for all instances 
- findings
    - generated from results of assessment run
    - a potential security issue or risk against instance
    - for each finding an explaination of the issue is provided 
## Integraztion with CloudWatch & CloudTrail
- cloudwatch
    - able to monitor agents and assessment runs 
- cloudtrail
    - all API calls performed by inspector are logged w/n CT
## Service Limitations and Costs 
- max 500 agents per assessment - hard cap
- max 50,000 assessment runs per account - soft cap 
- max 500 assessment templates - soft cap
- max 50 assessment targets - soft cap 
- cost 
    - based on number of instances scanned, specifically the amount of time, per month - charged per instance 

# AWS Trusted Advisor
## What is AWS Trusted Advisor
- helps optimize inffrastructure
- helps in making decisions based on best practices 
- main function: recommend impreovements across AWS account to optimize and streamline account
    - cost optimization
    - performance
    - security
    - fault tolerance 
    - service limit 
        - warns when resources reach 80% of service limit quota
- has a list of control points and checks to see if account is lined up with best practice 
- acts as automatic auditor across account 
- 115+ best practices checks    
    - list of available checks is based on support agreement w AWS
        - full access is provided with business and enterprise accounts 
            - also able to track most recent changes to AWS account + display at top of dashboard
    - security has 6 core checks available to all tiers 
- features available to everyone
    - trusted advisor notification
        - opt-in or opt-out feature that tracks resource check changes and cost saving estimates over the course of a week & emails 3 people
    - exclude items
        - exclude specific resources from appearing in console w/n specific check 
    - action links
        - hyperlinks associated w many of the items w/n checks + allow quick access to resource in question
    - acces management
        - tightly integrated to IAM; full-access, read only, restrict access to specific categories, checks, and actions 
    - refresh
        - data is automatically refreshed if data is more than 24 hours old
        - can perform manual refresh 5 minutes after the last refresh
## Reviewing Checks & Taking Action 
- dashboard
    - shows the five categories & three icons under each category 
        - if icons are grey, no checks have met an alert criteria to activate the icon (e.g., to low of an account level for scans to occur)
- for each check, there's four bits of information
    - description and use
    - alert criteria
    - recommended action: high-level suggestion on steps & action to rememdiate
    - additional resources 
- security checks
    - security groups - specific ports unrestricted
        - assesses SGs to see if there's unrestricted traffic allowed (e.g. from 0.0.0.0/0)
        - able to exclude SGs from the check in the TA console 
    - IAM use
        - checks if using IAM service (rather than just root)
    - MFA on root account 
        - logging in as root account should have add'l levels of authentication 
        - helps protect AWS account 
    - Amazon EBS Public Snapshots
        - checks if any snapshots are public
        - if snapshots are public, other folks would be able to view any data w/n if it's not meant to be public 
    - Amazon RDS Public Snapshots
        - checks if any RDS snapshots are public
- service limit checks 
    - checks w/n category assess when service limit reaches 80%
    - doesn't support every service 

# Understanding Amazon GuardDuty
## What is Amazon GuardDuty
- regional-based intelligent threat-detection service
    - users can monitor account for unusual behavior from CT event logs, VPC flow logs, DNS logs 
    - powered by ML
        - can identify behavior-based issues
        - best pracitces
        - blocking from known bad sources
    - provides auto and continuous security analysis
    - findings are sorted by severity
- doesn't require agents or software on resources
- can link multiple AWS accounts
## Components and Configuration
- data sources
    - CloudTrail Event logs
        - generated by CT, about API calls 
    - VPC flow logs
        - store network traffic info w/n VPC; in & out
    - DNS query logs    
        - contain queries that DNS resolvers forward to R53
        - contain requested domain, timestamp, record type, response code 
- machine learning 
    - gets better as time goes on & a baseline is able to be established
- list management
    - upload lists of trusted IPs and threats 
    - can only have ONE active trusted IP list at a time
    - may have 6 active threat lists 
    - only need to provide name of list, S3 location, and data format 
- GuardDuty Findings
    - found threats are listed as a finding w/n GD dashboard 
    - findings elements 
        - finding summary
            - finding type, severity, region, account ID, resource ID, time of detection, which threat list was used (if applicable)
        - resource affected
            - provides info about affected resource in detected threat
        - action
            - info about action that resulted in threat
        - actor
            - data relating to source of threat (IP, geographical info, port, domain)
        - add'l information
            - info on which threat list was used to detect threat 
            - if activity considered to be unusual
    - severity
        - each finding associated w severity level & score
            - high: 7.0-8.9
                - assumes security breach has occured & must be addressed immediately
            - medium 4.0-6.9
                - GD has detected suspicious activity that could escalate into a threat
            - low 0.1-3.9
                - issues that were detected, and may need to be addressed to prevent from occuring again 
## Managing Multiple Accounts
- able to have one account act as master and all other accounts as members & view findings in central location
- trusted IP lists and threat lists w/n member accounts are not used w/n master account
- master account give added controls like suspending GD w/n member accounts
    - able to suspend GD, but can't disable
- setup
    - add AWS account from w/n master account
    - send invitation to member accounts
    - accept inveitation from w/n member account 
        - can only accept one invitation 
## Managing Permissions
- access GD dashboard
    - perms req'd to access dashboard & enable GD
- enable GD
    - user needs access to GD & IAM perms to allow GD to have the proper service-linked role 
    - policy for user to use GD is AmazonGuardDutyFullAccess 
        - doesn't allow adding the lists, user must be able to do a couple more IAM things 
        - AWS has a template of a policy that allows true full access, but it's not managed 
        - AmazonGuardDutyReadOnlyAccess provides read-only perms for users to review findings 
        - GD uses AWSServiceRoleForAmazonGuardDuty when GD enabled 
- manage trusted IP & threat lists
## Understanding Amazon GuardDuty Findings
- in the finding, can filter by clicking on the magnifying glass with the +, and it adds it to the filter bar 
    - can save filters 
## Benefits to the Enterprise
- intelligent threat detection service that performs continual and automatic analysis and threat detection 
    - powered by ML, utilizes multiple threat detection feeds
- high-level security regardless of deployment size
    - provides same level of detection w/n global enterprises and small-scale deployments
    - implementing threat detection system in traditional env is very costly
    - minimal cost to observe all instances
- centralized management
    - aggregate findings into single master account
    - makes management easier
- no agents required
- no upfront costs
    - only pay for processing of log files 
    - click 'enable' and it starts working
- automation of rememdiation
    - can use CW event rules in conjunction w lambda 
    - able to trigger auto responses & quickly lock down resource by restricting permissions 
## Costing
- CloudTrail Event Analysis
    - per 1 million events/mo
- VPC flow logs and DNS log analysis
    - per GB of log analyzed per month
- able to use service free for first 30 days & see how much it would have cost to help estimate ongoing cost 
## Partner Offerings 
- vendors that focus on monitoring and security and provide services that interact with GD 
- Alert Logic Cloud Insight Essentials for AWS
    - allows gaining add'l insight into GD findings
    - helps respond to findings faster by providing further intelligence about threat
    - produce reports to analyze threat detection findings 
- CrowdStrike
    - integrate their threat intelligence feeds used w/n CW to GD
    - GD can pull data + info from CS which uses AI
- Trend Micro
    - Deep Security agent software that can be installed on EC2 to protect against threats
    - uses CW + lambda triggers to invoke Deep Security
- These are just a sample of the partners 

# Amazon Macie
## How to Find PHI and Sensitive Data in Your S3 Buckets with Amazon Macie 
- Macie: managed ML pattern matching service that helps with data security and privacy 
- can find PII and protected financial information
- able to take actions with lambda & step functions
- constant discovery of data w/n S3
    - creates service-linked role to
        - create inventory of S3 buckets
        - provide statistical data
        - monitor and evaluate buckets
        - check buckets for sensitive data 
- saves metadata and calculates statistics to make assessments of data
- can check for unencrypted buckets, publicly accessable, and shared buckets
- metadata automatically refreshed once every 24 hours
    - can be manually refreshed every 5 minutes 
- bucket policy findings
    - when Macie finds something, it creates a policy finding to be reviewed 
    - S3BlockPublicAccessDisabled
    - S3BucketEncryptionDisabled
    - S3BucketPublic
    - S3BucketReplicatedExternally
    - S3BucketSharedExtnerally
    - each finding includes severity rating, general information, and available for 90 days 
    - able to view findings in Macie Console, Macie API, AWS EventBridge, AWS Security Hub 
- since findings can be discovered programmatically, changes can be made auotmatically
### How to Discover Sensitive Data Within Buckets 
- create and run snsitive data discovery jobs
    - able to analyze objects in buckets for sensitive content
        - financial information
        - personal information
        - national information
        - medical information 
        - credentials and secrets 
    - report sensitive data & overall analysis
    - can be scheduled to run once, daily, weekly, etc 
    - managed data identifiers
        - built-in set parameters
        - curated and built by AWS
        - currently list defined by GDPR, HIPAA, PCI DSS, etc
    - custom data identifiers
        - created by customer
        - can include regex, severity data
        - can be used to supplment managed data identifiers 
- findings categorized by what bucket they were in and how they were found 
    - able to suppress findings as needed
### analyzing encrypted objects
- Macie can decrypt objects with the role, based on the encryption used
    - e.g., can decrypt SSE-S3, SSE-KMS fairly easily
    - for CMK-KMS, needs permission to the key 
    - cannot decrypt SSE-C
        - can only report metadata on object
    - cannot decrypt client side encryption
### Supported file formats
- big Data
    - .avro, .parquet
- compression/Archive
    - .gz, .gzip, .tar, .zip
- documents
    - .doc, .docx, .pdf, .xls, .xlsx
- text
    - .csv, .htm, .html, .json, .jsonl, .tsv, .txt, .xml, and other non-binary text files 
- can extract files and look at up to 1 million files and up to a depth of 10 levels
- video and pictures cannot be observed
### Integration with Organizations
- able to establish Macie Administrator account and run data discovery jobs across all accounts
    - can only have one Macie admin account
    - if Macie Admin account is changed, all other accounts are removed 
    - once an account becomes a member, it can not remove itself from membership 
- able to view all findings in all other accounts
- can have up to 5,000(!) members
- recommended to not be the same account as the organization root account 
### Costs
- number of S3 buckets evaluated
    - per bucket - $.10 per bucket/month
        - prorated per day
- quantity of data processed 
    - $1/gb/mo, and decreases as more data is processed

# Overview of Amazon CloudWatch
## What is Amazon CloudWatch?
- global service designed to be a window into health and operational performance of apps & infrastructure 
    - monitor & review performance
    - can trigger automatic responses 
- components 
    - CW Dashboards
        - build & customize page using different widgets 
        - resources can be from multiple regions 
        - can be shared w other users - even those not in the account 
    - CW Metrics + Anomaly Detection
        - metrics are key component and fundamental to the success of CW
            - enable tracking metrics over time 
            - different services offer different metrics
        - by default, everyone has access to a free set of metrics that are collated over 5 minutes
        - can collate data across the metrics every minute for a fee 
        - custom metrics are regional 
        - anomaly detection: CW implments ML against metric data to detect activity outside of the baseline
    - CW Alarms
        - tightly integrated w metrics 
        - allow automatic measures to occur based on metrics 
        - states
            - ok: metric w/n threshold
            - alarm: metric exceeded threshold
            - insufficient_data: waiting for info
        - can integrate w dashboards
    - CW EventBridge
        - extension of CW events 
        - connect applications to variety of targets (typically AWS services) to allow real-time responses to events
        - event: anything that causes change to env or app 
        - helps implement event-driven architecture in a real-time decoupled env 
        - elements
            - rules: filter for incoming stream of event traffic 
                - can route traffic to mulitple targets
            - targets: where events are sent by rules 
                - all events received in json
            - event bus: component that receives the event from apps 
                - rules associated with the bus 
                - default bus available, and other buses can be created
    - CW Logs
        - centralized location to store logs from AWS services that have log output 
        - acts as a central repository for real-time monitoring of log data 
        - requires unified cloudwatch agent that can collect from linux or windows - this is in addition to regular logging 
    - CW Insights  
        - can use to monitor log stream in real-time
        - types
            - log insights: analyze logs captured by CW logs at scale in seconds using interactive queries and delivers visualzations
                - can use to filter log data to get specific data 
            - container insights: collate and group metric data from container services + apps 
                - EKS, ECS
                - capture and monitor diagnostic data for add'l insights to issues w/n containers 
                     - can be analysed at cluster, node, pod, and task level 
            - lambda insights: gain deeper understanding of apps using lambda
                - gathers and aggregated metrics related to lambda to help monitor + troubleshoot serverless apps 
                - have to enable the feature per lambda function

# Building CloudWatch Dashboards 
- quickly display key information
- CW also has automatic dashboards on a service-by-service basis
- two ways to create dashboards: GUI or programatically
    - eight widget types
        - line chart
        - stacked area
        - number 
        - bar chart 
        - pie chart 
        - text: free text w markdown formatting
        - log tables: explore results from logs insights
        - alarm status 
    - able to apply math to data in dashboards 
    - json template of dashboards can be a bit challenging 
        - requires the location and data to be written 
- able to add annotation to graphs 
    - vertical and horizontal annotations can be added 
- can link w different dashboards in other regions and accounts
    - must enable cross-region or cross-account connections & other account must accept
    - sharing methods
        - share just one dashboard with a specific region or account 
        - share dashboard(s) publicly
        - connect all dashboards to SSO provider (like AD) to allow users from the SSO to be able to see the dashboards 
            - must be integrated with cognito
- cost
    - 3 dashboards w 50 widgets
    - $3/dashboard for larger than that 
- recommendations
    - make most important graphs the largest 
    - avoid plotting too much data in a graph
    - use horizontal annotations to show normal min and max values 

# How to Implement and Enable Logging Across AWS Services
## The Benefits of Logging
- without logging, there could be a delay in resolution fo the incident and the safeguarding of the env
- logs generally contain a huge amount of info retained on persistent storage
- audit control
    - often contain lots of metadata like date-stamps, source info (IP address, usernames)
- incident resolution
    - use logs to ascertain state of env before/after and during incident
- monitoring & alerting
    - monitoring allows quick identification of potential issues & get alerts 
- trend analysis
    - build a performance baseline to establish what's routine, and be able to identify threats & anomalies easier
- understanding infrastructure
    - understanding how infra is performing and communicating is key
    - having more data far outweights the disadvantages of not having enough 
## CloudWatch Logging Agent
- CloudWatch Logs
    - CW: used to collate and collect metrics on resources, monitor performance & respond to alerts
    - able to collect logs of apps & AWS services
    - able to monitor log streams in real-time
- unified CW agents
    - after installed, able to collect logs from EC2 instances & on-prem servers (in addition to std metrics)
- CW agent installation
    - create & attach role to instance so CW can collect data from instances & interact w ssm
        - need a role to install agent & to communicate w parameter store w/n ssm to store a config info file of agent
            - only one instance needs to be able to communicate w parameter store - best to remove this role after the config is written
            - cloudwatchagentadminpolicy & amazonec2roleforssm policies for the add'l perms for ssm
            - cloudwatchagentserverpolicy & amazonec2roleforssm policies to install agent and send data to CW 
    - download & install agent
        - on the instance w the admin policy (should only be temporarily attached)
            - download CW agent (instance needs access to agent)
            - agent may already be installed on certain AMIs
        - easiest to do it via SSM 
            - ssm > run command > run command > AWS-ConfigureAWSPackage
            - select instance to install on 
            - package: AmazonCloudWatchAgent
            - also able to do it from CLI (this page generates the command as well)
    - configure & start agent
        - on the first instance, must create CloudWatch Agent Configuration File
        - can be created or via the wizard 
            - wizard: `sudo /opt/aws/amazon-cloudwatch-agent/bi/amazon-cloudwatch-agent-config-wizard` 
                - one of the questions is 'do you want to store the config in the SSM parameter store', which then stores it in SSM and allows future read-only type instances be able to pull the config 
                    - may need credentials to upload to parameter store 
        - after the file is in SSM, go to SSM > run command > run command > `document name prefix: equal: AmazonCloudWatch-ManageAgent`
## CloudTrail Logging 
- AWS CloudTrail: records & tracks all AWS API requests made 
- captures request as an event and records this event w/n log file that's stored in S3 
- CT records add'l metadata like identity of caller, timestamp, source IP addr 
- log files
    - written in JSON
    - when API captured, associated w event & written to log
    - new logs created every 5 minutes
    - logs delivered to S3 buckets ~15 minutes after API called 
    - important attributes captured: eventName, eventSource, eventTime, SourceIPAddress (of requester who made API call), userAgent (method of request, console, root, lambda), userIdentity (add'l info on identity that made request)
    - naming format
        - AccountID_CloudTrail_RegionName_YYYMMDDTHHmmZ_UniqueSTring.FileNameFormat
            - random 16 character string used to CT as identifier
            - format json.gz by default 
    - s3 bucket folder structure
        - BucketName/prefix/AWSLogs/AccountID/CloudTrail/RegionName/YYYY/MM/DD
        - especially useful when multiple AWS accounts are delivering to the same bucket 
            - to aggregate logs, enable CT in AWS account, apply perms to destination S# bucket allowing cross-account access
            - create new CT & use bucket from another account 
            - to allow access to users to read the logs relating to their CT logs, have them use read-only roles to view only the logs from their account CT 
- CT log files security
    - log file integrity validation
        - allows verification that log files have remained unchanged since CT delivered them to S3 
            - typically for security & forensic investigation
        - when log file delivered to S3, CT creates a hash for it 
            - in addition to creating the hashes, CT creates a digest file every hour to help verify log files 
            - verification of log files can only be done via CLI 
## Monitoring CloudTrail with CloudWatch
- CT can send logs to CW logs, which allows metrics & thresholds to be configured
    - any event can be monitored; successful & unsuccessful API calls can be tracked 
- configure CT to use CW
    - make new CT use a new or existing CW log group
    - need a role & policy to allow CT to deliver to CW
        - CT needs to be able to CreateLogStream, PutLogEvents, then can deliver to CW logs 
        - role CloudTrail_CloudWatchLogs_role automatically made for CT to be used
        - CW logs can only accept items up to 256KB in size - larger than that won't be delivered 
    - CW must be config'd to perform searches on CT logs 
## S3 Access Logs
- collate data based on who has been accessing an s3 bucket
    - tracks the following metrics 
        - source bucket that was accessed
        - timestamp of events
        - identity requesting access to object in bucket
        - action performed w object 
- by default, access logging not enabled
- configuration based on source bucket & target bucket
    - source bucket: bucket to log requests for
    - target bucket: bucket to write logs to
    - recommended the buckets are different
    - buckets must be in the same region
    - needs write access for log delivery group
        - in the console, automatically created 
## CloudFront Access Logs
- CloudFront: speeds up distribution of static and dynamic content
    - requests routed to the edge location w lowest latency
    - can record the requests to S3
        - charged for storage on S3
- CF Access Logs
    - capture data over period of time + amount of log files generated depend on amount of requests recived
    - logs not written to S3, simply stored there
- enable: CF > general > logging: on
- CF needs permissions to S3 to write
    - needs FULL_CONTROL of the ACL, s3:GetBucketAcl, s3:PutBucketAcl
- Log files
    - depending on delivery type, the log output will vary
    - RTMP is depreciated
        - data/timestamp + which edge location received request
        - source metadata including ip 
        - event being carried out (Play, Pause, Stop)
        - URL of page where SWF file is linked 
    - web delivery info
        - data/timestamp + which edge location received request
        - source metadata including ip 
        - HTTP access method (PUT/DELETE/GET/etc)
        - HTTP status code of request
        - distribution domain name
        - encryption & protocol data 
- cookie logging
    - if enabled w/n distribution, CF will include all cookie info w CF access log data 
    - only if origin on distrubtion points to anything OTHER than S3, like EC2 (s3 does not process cookie data)
## VPC Flow Logs
- vpc flow logs capture IP traffic info that flows w/n VPC
- helps to resolve incidents w network communication & traffic flow
- log data is sent to CW logs 
- limitations
    - w VPC peered connections, can only see logs of peered VPCs w/n same account 
    - can't retrieve info from resources w/n EC2-classic env
    - once flow log has been created, it can't be changed 
    - traffic not monitored
        - DHCP traffic w/n VPC
        - traffic from instances destined for Amazon DNS servers
        - traffic destined to the IP addresses for VPC default router
        - traffic to and from 169.254.169.254 (metadata), 169.254.169.123 (time sync service)
        - traffic related to Amazon Windows activation license from a windows instance
        - traffic b/w NLB ENI + endpoint network interface 
- VPC Flow logs
    - can be created against three resources
        - ENI on instance
        - subnet w/n VPC
            - data captured for all network interfaces
        - VPC
            - data captured for all network interfaces
- publishing data to CW
    - every ENI that publishes data to CW log group uses a different log stream
    - w/n each stream there is flow log event data that shows content of log entries 
    - each log captures data during windows of ~10-15 minutes
- permissions
    - role needed to setup and config VPC flow log
    - VPC flow log needs to assume role to deliver logs to CW 
- flow log record
    - version  account-id  interface-id  srcaddr  dstaddr srcport dstport protocol  packets  bytes  start end  action log-status 
## AWS Config Logging
- what can AWS config do
    - capture resource changes 
    - act as resource inventory
    - store configuration history
        - uses configuration items (CIs) to collate and produce a history of changes to a particular resource
        - info can be accessed thru CLI or console 
        - sends a config history file for each resource type to S3 every 6 hours that contains all CI changes for resources
        - CI stores config info, relationship info + other metadata in a json file
            - CI created every time supported resource has change made to config
            - for every CI generated, there will be five sections
                - Metadata: version and config ID, MD5Hash for comparision, time of capture and state ID
                - Attributes: unique resource ID, key-value tags, resource type, ARN
                - Relationships: description of relationships to other resources
                    - e.g., for ec2: vpc it resides in, etc
                - Current Configuration: displays info from 'Describe' or 'List' calls from CLI
                - Related Events: displays related AWS CT event ID 
            - can aggregated configuration history files into same s3 bucket
    - provide a snapshot of resource configurations 
    - notifications about changes 
    - provide AWS CT integration 
    - enforce rules to check compliancy 
    - security analysis
    - identity relationships between resources 
## Filtering & Querying data with Amazon Athena 
- can use Amazon Athena to query data w SQL w/n S3 to search for specific entries 
- must create DB, either with SQL, or in Catalog Manager with a wizard, and a S3 bucket to store the Athena DB (not for querying yet)
    - works like regular DB, and tables and such can be created and point to a S3 bucket to query from
- basically everything done with SQL
- queries can be saved with a name and description 
- can view past executed queries in history - both the command & results of the command  

# KMS 
## What is Encryption
- unencrypted data: aka plaintext/cleartext
- data encryption: mechanism in which info is altered, rendering the plain text data unreadable 
    - plaintext turned into cyphertext 
    - need an encryption key to covert back to plaintext
    - longer the key, more difficult it is
- symmetric cryptography: single key used to encrypted & decrypted 
    - the problem is if a third party gets the key, since the key has to be shared 
    - KMS can function as a central repository for storing this key for additional security 
    - faster than asymmetric encryption
- asymmetric encryption
    - encryption key (private key)
    - decryption key (public key)
        - able to be shared - doesn't need to be sent securely
        - w/o private key, unable to open it 
## An Overview of AWS KMS
- KMS: managed service used to store and generate encryption keys 
    - other services able to use KMS for encryption 
- AWS has no access to custom keys & cannot recover deleted keys
    - only responsible for the hardware hosting the service 
- core components 
    - AWS KMS keys: encrypt and decrypt data
    - customer managed keys: created, managed and controlled by customer
    - AWS managed keys: managed by integrated AWS services
    - AWS owned keys: managed by AWS, used across multiple accounts; not tied to individual account
    - data keys: encrypt data outside of KMS
    - HMAC keys: symmatric key to create & verify HMAC codes 
    - only able to encrypt data at rest with these keys 
        - data in transit needs method like SSL
        - data encrypted at rest would remain encrypted when sent to others 
## Components of the KMS service 
- AWS KMS keys
    - primary keys w/n KMS that can be used to perform crypto ops
    - key can be used to generate data keys
    - when generated, created as symmetric 256-bit AES-GCM encryption key
    - will live in KMS permanently
    - by default, AWS services use symmetric encryption
- assymetric keys used when encryption needed outside of KMS
- key types
    - customer managed keys (CMKs)
        - asymmetric keys
        - provide greater key control
        - create key policies 
        - admin functions available: enable/disable, manage rotation, add tags, create aliases, manage deletion
    - AWS managed keys
        - automatically generated
        - integrate w KMS
        - perform same function as CMKs
        - can be viewed w/n KMS
        - easily identifiable: aws/servicename is the standard naming
        - users cannot manage key in any way
    - HMAC keys
        - Hash-based Authentication Code
            - take message data + HMAC key that's associated w metadata of object to check integrity & authenticity of data 
        - confirms to standards sset by RDS 2104
    - Data keys
        - generated by KMS
        - meant to be used outside of KMS
        - uses symmetric encryption; it uses a plaintext and encrypted version of the same key 
    - Data key pairs
        - use asymmetric encryption
        - supported type 
            - RSA, elliptic curve, HM
        - private key store in KMS & encrypted by KMS key
        - plaintext private key + encrypted version created
        - encryption: public key + algorithm = cyphertext
        - decryption: data keys + plaintext keys + algorithm = plaintext 
    - Key Material
        - element used as part of crypto algorithm
        - private key material
            - must be protected
            - symmetric encryption required
        - public key material
            - asyemmetric encryption
            - public key 
        - key material storage for symmetric keys 
            - AWS KMS
            - external key manager
            - CloudHSM
    - key rotation
        - should be implemented for CMKs
        - can be done automatically & managed by AWS 
            - key doesn't change; key material associated with key changes 
        - for AWS managed/owned keys, AWS does automatically 
        - all previous key information is saved in rotation - data encrypted before the rotation is still accessable, and uses the cryptographic information of the key from when it was originally encrypted 
    - key policy
        - security feature w/n KMS that allows defining who can use and access particular keys 
        - resource-based policies
        - different policies can be created for different KMS keys
        - permissions defined w/n JSON key policy document 
    - grants
        - temporary-based policy
        - resource-based policy
        - allow delegation of subset of user's access to KMS key for another principal, such as another user w/n AWS account 
        - less risk of someone altering access control perm's for the KMS key
        - grant created & applied to KMS key for each principle requiring access 
## AWS KMS Permissions and Key Policies 
- to use IAM policies, have to allow the use of IAM policies w/n KMS key policy
    - enabling the use of IAM doesn't provide access, just allows policies in IAM to govern user access to the key 
    - access given to root, with the upside of always being able to have access to key at some level 
- KMS key policies
    - resource based
    - contain info like
        - IAM user permissions
        - who can administer key
            - can only perform administrative actions with the key, not cryptographic actions (although they can do both if the permissions are set up correctly)
            - can specify if they can delete key
            - have ability to update key policy and allow themselves to use the key
        - cryptographic operations
        - grants 
    - JSON based and largely similar to IAM policies in format 
    - allow use of key to key users
    - grants: allow attachment of persistent resources
        - the way to allow users to provide grants 
        - grants must be made via KMS APIs; not possible in the console  
        - only have access to single KMS keys
        - can only be granted to single users
        - can only have 'allow' permissions, not deny
        - permissions may take some time to propogate; tokens are eventual consistency
        - retire: use when grant is no longer needed
        - revoke: use if key becomes compromised
        - grants do not expire; valid until retired or revoked  
- KMS events will not appear in event history 
## KMS Access: Policy Evaluation Logic 
- policy types 
    - key policy
    - IAM policies
    - grants
- least privileged access: any deny has overarching importance, and user needs explicit access 
## Sharing CMKs Across Multiple AWS Accounts 
- Custom master key
    - can create data encryption keys for external data encryption 
    - managed by AWS: used by AWS services (S3, SSE-KMS)
    - managed by customer: 
        - greater flexibility
        - manage the key 
            - rotation
            - governing access
            - key policy configuration
            - enable and disable key
- access control
    - identity-based IAM policies
    - resource-based access 
    - to manage access to CMKs, key policy must be used 
    - must use resource-based key policy where the CMK resides along w IAM identity-based policy in AWS acct that wants to access the CMK
    - can only edit key policies for keys that you have created 
        - can't share managed CMKs b/w accounts 
- key policies
    - resource-based policies tied to CMK
    - KMS creates a default key policy when the key is created in the console 
    - define permissions for
        - key administrators: administer CMK, but don't use for encryption
        - users: can access CMK + perform encryption
    - to allow another account, add IAM users from the other account in the policy JSON
        - users w/n the external account need IAM users/roles in their account to be set & associated to be able to use the CMK 
        - need the ARN of the key to add to the policy in the other acct 
        - once connected, key won't show in console (e.g. in KMS option in S3); will have to use ARN to use it 

# Sharing Secrets Between Multiple Accounts Using AWS Secrets Manager
- secrets manager  
    - secret: password, API keys, plaintext; something to remain hidden from world
    - able to remove hardcoded secrets w/n app and replace w API call to secrets manager 
    - enables easier secrets rotation
    - integrates closely w AWS services 
- access to secrets
    - goverened by fine-grained IAM identity-based policies + resource-based policies 
- sharing secrets b/w accounts
    - with the goal of having a single account with all secrets stored centrally 
    - account with secrets, key policy needs to allow user/role from other account to use the key 
        - have to set a resource-based policy on the secret, but can only do it via a JSON document applied via CLI 
    - account using the secret, role/user needs policy allowing reading of the secret and decryption of KMS to be able to actually use the secret

# CloudHSM
## What is CloudHSM
- HSM: hardware security module
    - physical, tamper-resistant hardware appliance used to protect and safeguard cryptographic material and encryption keys
- provides Federal Information Processing Standards (FIPS) 140-2 level 3 (used for document signing, CAs)
- physical single-tenant device
- used for secure encryption key management 
- create, store, manage cryptographic keys
- ability to use cryptgraphic hash functions (HMACs)
    - symmetric & asymmetric
- able to manage HSMs to a greater degree than KMS HSMs
## Understanding AWS CloudHSM Architecture & Implementation
- begin by creating a cluster over multiple AZs for HA
- any requests to cluster load balanced b/w HSMs in cluster 
- ENI placed in customer-owned VPC, and connects to an AWS-owned CloudHSM-owned VPC
- creates a service-linked role and SG for the cluster w ports 2223-2225
- provisioned in uninitialized state 
- once initialized, able to connect via EC2s w/n subnets/vpcs
- add instance to cluster SG
    - must enable 22/3389
- install AWS CloudHSM client software on instance 
## Access Control
- users on HSM devices + need IAM permissions
- types of users on HSM
    - precrypto office (PRECO)
        - first HSM connected to has this user which is a temporary user with temp credentials of read-only access to cluster
        - part of activation process of cluster PRECO PW will be changed, and becomes CO 
    - crypto office (CO)
        - can perform user management tasks
            - creation & deletion of users
            - changing users passwords
        - perform administrative level cryptographic operations 
            - zeroize data on HSM
            - obtain HSM details (IP addresses, models, serial numbers)
            - view & determine syncrhonization status across cluster 
    - crypto user (CU)
        - used to perform cryptographic operations and key management functions in cluster
            - create, delete, import/export + share of crypto keys
            - perform encryption & decryption
            - signing & verifying 
        - also able to zeroize data & get HSM details & sync status 
    - appliance user (AU)
        - performs cloning and sync across cluster
- HSMs designed w physical tamper detection + response processes 
    - performs key deletion if compromise detected
    - resistant against brute force attacks + will lock user out if identified 
## Using CloudHSM as a Custom Key Store in KMS
- KMS: can create custom key store, which are storage locations to store and protect crypto key
    - default key stores managed by KMS & stored on HSMs managed by AWS
    - can create a custom key store and have full management over CloudHSM store
    - benefit: wide integration w other AWS services w minimal configuration 
- custom key store obtains key material from CloudHSM cluster, and able to leverage the power of KMS 
- each HSM cluster can only be associated w one custom key store
    - must upload trust anchor certificate for cluster to KMS to create custom key store 
- a user must be created for KMS for it to access crypto information on HSM cluster 
## Monitoring & Logging 
- pushes metric data to CW 
    - HsmUnhealthy
    - HsmTemperature
        - machine will shut down if temp gets to 110ºC
    - HsmKeysSessionOccupied
    - HsmKeysTokenOccupied
    - HsmSslCtxsOccupied
    - HsmSessionCount
    - HsmUsersAvailable
    - HsmUsersMax
    - InterfaceEth2OctetsInput
    - InterfaceEth2OctetsOutput
- CT can track and record API calls for CloudHSM
- CW logs can track audit logs 
    - generated by CloudHSM clients using the CloudHSM client daemon
    - retrieved by viewing file on client or by entering a command 
    - can't be disabled or turned off, either locally or on the way to CW logs 
    - allows full audit of all actions and requests that have made changes to HSM

# AWS Encryption for Data Analytics
## Amazon S3 and Amazon Aethna Encryption
- S3 encryption options
    - SSE
        - used for securing data at rest
        - data encrypted at object level before written to disk
        - forms
            - SSE-S3 (amazon s3 managed keys)
                - Amazon S3 uses unique key to encrypt each data object & the key is encrypted w Master Key 
                - objects encrypted w AES-256 (which is symmetric), which is fine, since AWS manages encryption & decryption 
                - works w S3 bucket policies (e.g., enforce SSE w conditions in policy)
            - SSE-KMS (keys managed by AWS via KMS)
                - have the option to select default AWS S3 CMK or choose a customer managed CMK
                - KMS CMK is used to encrypt the data keys, not the actual object data itself 
                - when uploading an object: request made from S3 to KMS, KMS returns two versions of data key, one in plaintext, and is used by S3 to encrypt object. The other key is encrypted and uploaded w the object 
                - decryption: S3 sends encrypted data key to KMS, KMS uses CMK associated to decrypt the data key, and KMS responds w plaintext key 
                    - plaintext key stored in memory and deleted after actions are copmleted 
            - SSE-C (keys managed by customer & provided to AWS)
                - customer must supply key and S3 service performs the encryption
                - must send customer-provided key w data object upload request using HTTPS
                - after encryption, AWS deletes the AES-256 key from memory and stores HMAC value
                - must use the same key to decrypt
    - CSE (client side encryption)
        - data encyprted before being sent to S3
        - CSE-KMS (CSE using KMS)
            - only need to supply CMK-ID to the S3 encryption client
            - when object uploaded, request is made by the client and KMS returns a plaintext and ciphered visions of a data key
            - when object retrieved, client sends the ciphered key to KMS to retrieve the matching plaintext version
        - CSE-C (client-side encryption using a custom client-side master key)
            - key is never sent to AWS
            - when uploading an object, master key must be provided to client 
            - master key will be used to encrypt a data key generated by the client, which will be used to encrypt the object data 
            - when object retrieved, the master key is used to decrypt the data key & object is decrypted 
- Encryption with Amazon Athena 
    - able to query S3 data that is already encrypted
    - it can encrypted the results of the query
    - the encryption of results is independent of the underlying queried S3 data 
        - i.e. can encrypt results of unencrypted data 
    - supports SSE-S3, SSE-KMS, CSE-KMS
    - doesn't support SSE-C, CSE-C
    - can only unencrypt objects that are in the same region 
## Elastic MapReduce (EMR) Encryption
- EMR: managed service comprised of a cluster of highly scalable EC@ instances to process and run big data frameworks
- can encrypt data at rest, in transit or both
    - the exist as a separate entity w/n EMR & can apply to future created clusters
- by default, instances w/n cluster don't encrypt data at rest
- BY DEFAULT, DOESN'T ENABLE ENCRYPTION AT REST 
- instances w/n EMR are created from pre-config'd AMIs
- must use EMR 5.7.0 to use custom AMIs and encrypt the root device volume 
- EMR encryption w EBS
    - if using EBS as persistent storage (not applicable to root volumes)
        - Linux Unified Key Setup (LUKS): specify KMS to be used as key management provider or use custom key provider
        - Open-Source HDFS Encryption: secure Hadoop RPC, uses SASL
            - data encryption of HDFS block transfer uses AES-256
- EMR encryption with S3
    - can use S3's encryption tools
    - supports SSE-S3/SSE-KMS or CSE-KMS and CSE-C (if data is encrypted before being sent)
    - encryption in transit using TLS cert provider
        - must provide pem to S3
- EMR application specific encryption
    - Hadoop
        - Hadoop MapReduce Encrypted Shuffle uses TLS
        - secure Hadoop RPC uses SASL (simple authentication security layer)
        - data encryption of HDFS block transfer uses AES-256
    - presto
        - when using EMR 5.6.0+ any internal comms b/w presto ndoes use SSL/TLS
    - tez
        - tez shuffle handler uses TLS
    - spark 
        - Akka protocol uses TLS
        - block transfer service uses SASL and 3DES
        - external shuffle service uses SASL
- EMR encryption w KMS
    - when using encryption at rest using KMS CMKs
        - ensure that role assigned to instance w/n cluster have relevant permissions to enable access to CMK
        - add relevant role to key users for CMK
- EMR transparent encryption w HDFS
    - offers encryption both at rest and in transit
    - data encrypted and decrtyped transparentingly w/o requiring changes to app code
    - each HDFS encryption zone has own KMS key; by default EMR uses Hadoop KMS, but alternative can be selected 
    - each file is encrypted by a different data key, which are encrypted w HDFS encryption zone key; not possible to move files b/w encryption zones 
## RDS Encryption
- during creation of RDS, encryption can be enabled at Configure Advanced Settings screen 
    - keys can be issued by KMS using AES-256
    - encryption can't be applied after DB creation
- to encrypt an unencrypted DB, 
    - create snapshot of unecnrypted DB
    - create encrypted copy of the snapshot
    - use the encrypted snapshot to create new DB
    - now have an encrypted RDS DB 
- RDS encryption
    - if KMS ke3y is disabled, will not be able to read or write to DB and RDS will move its instances to terminal state
    - must reinstate the KMS key and recovery DB from backup
    - read replicas follow same encryption pattern as defined by the DB source 
- RDS encryption mechanisms
    - Oracle and SQL Server Transparent Data Encryption (TDE)
        - can be used in addition to KMS, but would impact performance of DB 
        - to use, DB must be associated to an option group
            - option groups provide default settings for DB & help w management
            - option groups only exist for oracle, mariadb, mySQL, and some versions of MSSQL server 
        - must add Oracle Transparent Data Encryption option to the group, and it can't be removed 
        - TDE Encryption modes
            - TDE tablespace encryption: encrypts entire table
            - TDS column encryption: encrypts single columns 
    - MySQL cryptographic functions 
    - Microsoft Transact-SQL cryptographic functions 
- RDS Encryption: Instance Types 
    - offers ability to encrypt instances across all regions other than China (Beijing) region, and across ~20 types of instances
    - applying encryption at rest for RDS simplified due to built-in app-level encryption option 
- encryption in transit
    - can be secured using SSL/TLS
    - recommended if required to abide by specific compliance or when data is sensitive
    - method how this works based on DB engine type
- RDS encryption w Oracle
    - can use Oracle's Native Network Encryption (NNE)
    - will encrypt all connections w DB
    - not possible to use SSL and NNE together 
    - to enable, add NATIVE_NETWORK_ENCRYPTION to DB options group 
## Amazon Kinesis Encryption
- Amazon Kinesis Firehose
    - delivers real-time streaming data to different service w/n AWS; can be useful for big data
    - fully managed by AWS 
    - receives data from data producer and delivers to destination
    - encryption
        - can be sent via HTTPS; when enters Kinesis, is unencrypted by default 
        - can implement encryption using SSE-KMS on S3
            - relevant perms must be assigned to a role for access 
    - even when sending data to redshift/ElasticSearch, data is stored in S3 and has the applicable encryption there
- Amazon Kinesis Streams
    - collects and processes huge amount of data in real-time
    - data can come from varity of sources 
    - encryption
        - able to implment SSE-KMS directly from producers
            - gives full at-rest encryption 
            - new data key generated every 5 minutes 
            - small latency of less than 100 micro seconds added to performance 
        - both producer and consume apps need perms to use KMS key
            - producer: something that adds data to Kinesis stream
            - consume: Kinesis app that processes data from stream 
## Amazon Redshift 
- redshift: managed service for data warehousing for big data solution
    - able to scale up to 1 PB
- Redshift Encryption   
    - offers encryption at rest using 4-tiered hierarchy using either KMS or CloudHSM
        - T1: the master key
            - managed by KMS or CloudHSM
            - integration w HSM device req's add'l steps to implement
        - T2: cluster encryption key (CEK)
        - T3: db encryption key (DEK)
        - T4: data encryption keys 
    - when encryption is enabled it can't be disabled and vice cersa
        - can only turn on encryption at creation
    - once cluster is encrypted, data, metadata and snapshots are also encrypted 
- KMS encryption for redshift
    - either use default KMS key or select another CMK
    - default key automatically made when encryption is chosen upon creation 
    - CMK known as master key on tier 1
        - redshift will send request to KMS for new KMS data key
        - KMS data key encrypted w CMK master key
        - encrypted KMS data key then used as the Cluster Encryption Key (CEK)
        - CEK sent to redshift and stored separately from cluster
        - redshift sends CEK to cluster over asecure channel & key stored in memory
        - redshift requests KMS decrypts T2 CEK
        - decrypted CEK also stored in memory
        - redshift creates random DEK and loads it into memory
        - decrypted CEK in memory encrypts the DEK which is also stored in memory
        - encrypted DEK is stored separately from the cluster
        - encrypted and decrypted CEK & DEK are stored in memory
        - decrtyped DEK encrypts the data keys generated by redshift 
- CloudHSM encryption for Redshift 
    - to work wth CloudHSM, must set up trusted connection b/w both HSM client and redshift using client and server certs 
    - using a key pair, redshift creates public client cert 
    - cert is downloaded and registered to HSM client & assigned to correct HSM partition
    - must config redshift w HSM ip addr, partition name/password, public HSM server cert
    - after info provided, redshift confirms it's able to use the connection 
- key rotation
    - redshift enables rotation of encryption keys for encrypted clusters
    - be aware: cluster will be unavailable for a short period of time during the key rotation process
    - during rotation
        - redshift will rotate CEK & CEK for backups
        - rotate DEK
        - put cluster into state of ROTATING_KEYS until process complete
    - perform key rotation w console
        - redshift > clusters > pick cluster > select db > rotate encryption keys > yes, rotate keys 

# Protecting Web Apps with AWS WAF, Shield, & Firewall Manager
## WAF
### What is WAF & what does it do? 
WAF: helps prevent web sites and web apps from being maliciously attacked by common web attack
patterns
1652
used to identify how Cloudfront distrubutions and ALBs respond to web requests
1653
filters HTTP and HTTPS requests distinguishing between legit and malicious users
1654
- WAF components
    - conditions
        - specify what elements of incoming HTTP(S) request to monitor for
            - cross-site scripting: scripts written to maliciously gain access to client-side data from another user via a web apo
                - scripts embedded w/n web pages that are normally trusted
                - can be data like cookies
            - geo match
                - specify which countries and geographic functions for WAF to filter on
                - if using geo restriction w/n CF to block country, then traffic from that country won't make it to WAF ip addresses
            - ip addresses 
                - specify a single IP addr or a range of IP addrs to allow or block
                - can be used in conjunction w geo match
            - size constraints
                - block traffic based on size of parts of requests. can define which part to look for
            - SOL injection attacks
                - can alter and read data w/n db and spoof identities
                - performed by inserting a SQL query via client into an entry field to a remote app db
            - string and regex matching
                - identify web requests based on strings contained w/n request itself
                - when creating a web ACL, can allow or block
    - rules
        - allows compliation of one or more conditions into a list, where each condition is ANDed to form the complete rule
        - requests must meet all the rules to help with more specific matching
        - types
            - regular
            - rate-based
                - count number of requests from a single IP over 5 minutes
                - When limit is reached, further requests are blocked 
                - if traffic drops below limit, requests are unblocked
                - must be >=2,000 requests, otherwise is just a regular rule adding conditions to rules
                every condition in rule has to be met for the action of the rule to be carried out
    - web ACLs
        - rules are added here
            - final decision if traffic is allowed or block
            - action applied for each rule: Allow, Block, Count
                - allow: request forwarded to CF distribution or ALB
                - block: request terminated
                - count: count number of requests that meet conditions w/n rule
                    - helpful in testing to see how much traffic meets this rule before making it allow/ block
            - rules executed in the order that they are listed w/n web ACL
                - usually listed whitelisted (allow), blacklisted (block), bad signatures (block)
### When and why should I use WAF?
- if delivering web content via CFt or ALB, recommended to implement WAF as an add'l layer of security 
- benefits
    - huge asset to web app arch
    - quicker and simpler to manage than standard WAF solutions
        - easy to manage via console or cli/apis
        - integrates w CW for monitoring and Lambda for automation
    - might help achieve higher level of security compliance 
    - the closer the detection systems are logically implemented to web app, the greater the risk of add'l vulnerabilities being exploited 
    - logically, sits b/w end user & CFt distributions
        - however, request will be received by CFt distribution first and then forwarded to associatd WAF web ACL
### WAF Demo
- cloudwatch metrics made for ACL and for rules 
- to attach to CFt, go to CFt console & go to general > edit to add WAF ACL
### Monitoring WAF
- in AWS WAF dashboard, able to view statistical info for web ACLs created 
    - can't generate reports here 
- integrating w CW
    - metrics reported in one minute intervals & kept for 2 week periods
    - sum count of
        - AllowedRequests
        - BlockedRequests
        - CountedRequests
        - PassedRequests
    - for each ACL, there will be an associated CW metric 
### Limitations of WAF
- 100 conditions of each type, except regex, which allows only 10 conditions (soft limit)
- 100 rules and 50 web ACLs per acct
- 5 rate-based-rules per acct 
- 10,000 requests per second for WAF w ALB 
- same web ACL can be assigned to different CFt distributions 
### WAF and CloudFront
- WAF relies heavily on CFt distributions
    - CFt does not rely on WAF
- WAF supports custom origins, allowing applying the same level of security to web infra managed outside of AWs
- associate b/w web ACL and CFt distrubtion can take ~15 min for Web ACL and rules to be propigated 
- when request blocked by WAF, CFt notified request was forbidden & returns 403 to browser
    - error doesn't provide any useful info to user 
        - can create custom 403 errors to guide users to issues for access 
- use combo of CFt config and WAF Web ACLs to process incoming requests leveraging settings from both services 
    - e.g. if CFt will not respond to certain methods, no need to also block those in WAF
### WAF Pricing
- number of incoming requests
    - $0.60 per million requests
- number of Web ACLs
    - not chargee xtra for assigning the same Web ACL to multiple distributions 
    - $5 per Web ACL per mo
- number of rules w/n each of Web ACL
    - $1 per rule per Web ACL per month 
- all charges in addition to using CFt
- no upfront costs, and not very expensive overall 
## AWS Firewall Manager
### Overview of Firewall Manager
- simplify managing WAF in multi-account env w simplicity and control
- able to protect all vulnerable resources across all of AWS accts w/n AWS organization
- prerequesites
    - AWS account must be parent of AWS organization, which must have been config'd w all features 
    - define which AWS acct will act as the firewall manager admin
    - AWS config must be enabled 
### Components of Firewall Manager
- WAF rules (same as rules in the actual WAF console)
- Rule Groups
    - allow group together one or more WAF rules that will have the same action applied
    - can create own group & add own WAF rules, or purchase existing rule groups via AWS marketplace 
    - can only contain block or count acionts (no allow action)
    - hard max of 10 rules per rule group 
- firewall manager policies 
    - after rule groups are created, this contains the rule groups 
    - hard limit of two rule groups: one custom, one from AWS marketplace  
    - $100 per policy per region per month 
## AWS Shield
### What is AWS Shield
- protect infrastructure against DDoS
- DDoS attacks
    - SYN flood
        - spoofed SYN packets sent to host, which sends SYN/ACK, but never receives ACK & leaves those requests open
    - DNS query flood
    - HTTP flood/cache-busting
        - send lots of requests to host, force content to be retrieved from originating server and not edge location 
- AWS Shield Standard
    - free: offers DDoS protection against common layer 3 & 4 attacks for S3 and CFt
- AWS Shield Advanced
    - offers protection to web apps running on EC2, CFt, ELB, route53
    - enhanced levels of DDoS protection offered compared to standard
    - access to 24/7 specalized DDoS respond team  
    - can view real-time metrics of any attacks against resources
    - protection against layer 3, 4, 7 attacks
    - cost protection as a part of the plan, and WAF is included in 
    - $3,000/mo 
    - account-specific
### Configuring Shield
- have to configure rate-based rules from WAF to help indicate DDoS attack is in progress 
    - only needed for ALBs and CFt
- pre-authorize AWS DDoS Response Team (DRT)
    - can allow DRT team access to resources to help in event of attack
    - must be subscribed to business or enterprise support 
    - team is given access by adding a role that they can assume 
- recommended to use CW + SNS + shield for notifications 
- global threat enviroment dashboard
    - shows number of attacks across AWS landscape 

# AWS VPC: Subnets and Routing
## VPC Subnets
### VPC CIDR Blocks
- subnetting: process of splitting CIDR block into smaller CIDR blocks 
- VPC creation requires IPv4 CIDR block
    - max block: /16 (65,531 hosts)
    - min block: /28 (11 hosts)
    - first available host address for VPC router
    - second available for AWS DNS
    - third available for future AWS use
    - remainder of addresses for host use
### Why Subnet your VPC? 
- logical network division
    - able to have SN for DB/app/web
- security
    - w logical division, allows for greater security mgmt 
- accessibility
    - split b/w private & public SN and have different controls for each 
- communication
- high availability
    - better to deploy resources across multiple subnets 
### VPC Subnets
- console info for subnets 
    - summary: provides summary of all metadata associated w subnet 
        - includes IPv4/6 CIDR, state, vpc, available IPs, az, route table, nacl, default SN (from default VPC) yes/no, auto-assign public ipv4/6 status
    - route table 
    - NACL: displays inbound & outbound rule sets 
    - flow logs
    - tags
### Public & Private Subnets
- public subnets have direct access to internet
    - IGW attached to VPC + added to SN default route 
    - instances w/n public SN will need public IP addr to communicate on internet
    - NACLs need to allow traffic in/out 
- ip addressing behavior
    - public ip addresses can be automatically or manually assigned to instance
    - by default, all subnets have automatic assignment disabled 
        - able to disable on instance if SN setting is automatic assignment 
    - must use EIP if the same IP addr is desired every time 
- private subnets have no direct access to the internet
### VPC Peering: Subnet Considerations
- allows connect two or more VPCs together as if they were part of the same network
- once established, resources in one can access resources in the other
- subnet considerations
    - vpcs w overlapping or duplicate CIDR blocks can't be peered
- it is not possible to create end-to-end communication of VPCs by daisy chaing them together
    - each VPC will only communicate w its peer 
### Flow Logs: VPC Subnets
- track traffic flow & troubleshoot network problems b/w VPCs, subnets, individual networking adapters 
## VPC Routing
### Routing Fundamentals & Route Tables
- routing: provides mechanism to allow network packets to be forwarded to the correct destination
- routing fundamentals
    - AWS creates & adds implicit router for VPC during CPV creation process
    - default route table, named 'Main Route Table' also created
    - main route table cannot be deleted & is implicitly associated w subnets 
        - able to set a new main route table; doesn't have to be the default one
    - subnets can be implicitly or explicitly associated w route table 
    - a subnet can only be associate w a single route table
    - a route table can be associated w multiple subnets 
- console info
    - summary: route table ID, explicit association, main yes/no, vpc 
    - routes: shows routing decisions made w/n routing table
        - destination: CIDR block for network to route to
        - target: gateway to route to
        - status
        - propogated yes/no
    - subnet associations 
        - can't use route table of another SN via daisy chaining 
        - under main route table, will show implicit and explicit associations
    - route propagation 
        - enable route propagation against virtual private gateway (VGW) attached to VPC
    - tags 
### Routing Priorities 
- longest prefix match: AWS will use most precise route available w/n route table to route traffic to specific destination
    - e.g., if there's routes for 192.168.0.0/16 and 192.168.1.0/24, will go to the /24 one 
    - exclusions
        - if route propagation is enabled for VGW & those propagated routes overlap the 'local' route - the local route will have precedence, even if propagated routes have LPM
        - if any propagated routes have the same destination as any static routes, LPM rule not aplpied. Route priority is executed against static routes in the following order
            - IGW > VGW > ENI > Instance ID > VPC peering connection > NAT gateway
                - read as, IGW has greater preferance than VGW, etc 
- route table limitations
    - soft limit of 200 routes per VPC
    - soft limit of 50 non-propagated routes (hard limit of 100)
    - each limit applies separately to IPv4 and IPv6
    - hard limit of 100 propagated routes per table 
### Routing: VPC Peering
- peering connections abbreviated w pcx
- subnets in both VPCs must include a route to subnets in the peered VPC using the pcx 
- CIDR block must not overlap for peered VPCs
- can peer to two separate VPCs that themselves have overlapping CIDR blocks
    - it's possible, but do try to avoid it... 
        - e.g. A connects to B, which is connected to A and C, and C is connected to B. 
            A and C both have the same CIDR range, and B has a separate one. Routing properly between A and C gets tricky when considering routing priorities 
    - peering does not support unicast reverse path forwarding 
        - i.e. if A and and C both have same CIDR range, and request comes from A, and they both have the same entry on the route table, the response would probably be routed to C
### Routing: VPN Connection via a Virtual Private Gateway
- required to set VPN connection between corporate network & VPC
- once VPG is attached, route tables for SN need to be updated to point to corporate network
- IPv6 not supported over VPG connection 
### Routing: Internet Gateways & NAT Gateways
- internet gateways     
    - public subnets must be able to route to IGW attached to VPC
    - IGW is means of communicating to internet fro mVPC 
    - IGWs are managed service
    - destination of 0.0.0.0/0 implies that any routes with unknown routes are sent to the internet 
- NAT gateways
    - allow instance w/n private subnet to initate a connection to the internet
    - access from internet cannot be initiated w instances w/n subnet behind NAT gateway
    - created per AZ, recommended to have multiple for HA 
### Routing: VPC Endpoints 
- virtual device which allow connection of VPC to other AWS services w/o using gateway
    - traffic remains w/n AWS global network
- S3 and DynamoDB supported
- doesn't impose risks of availability or bandwidth across VPC
- creating new endpoint automatically adds an entry to main route table 

# AWS Security Best Practices: Abstract & Container Services 
## Abstract & Container Services
- container service characteristics
    - run on separate infrastructure instances, such as ec2
    - AWS responsible for OS + platform 
    - managed services provided by AWS for the actual app which are seen as 'containers'
    - customer responsible for management and security of
        - managing network access security
        - platform level IAM
    - examples: RDS, EMR, elastic beanstalk
    - provide greater control & responsibility to customer 
- abstract service characteristics 
    - service is removed (abstracted) from the platform or management layer
    - accessed via endpoints using AWS APIs (typically not assigned AZs)
    underlying infrastructure, OS, platform - managed by AWS
    - provide a multi-tenant platform on the underlying infra
    - data isolated via security mechanisms
    - strong integration w IAM
    - examples: S3, DDB, Glacier, SQS
- AWS shared responsibility model 
    - which security controls are AWS responsibilities and which are the customers
    - boundaries vary b/w services 
    - three models
        - infrastructure service model
            - AWS: security of the cloud (foundation services, global infra)
            - customer: security in the cloud (data, IAM, OS config, encryption)
            - how and when to apply security controls is not AWS' responsibility
        - constainer service model
            - AWS: platform & app management, OS & network config, foundational services, global infra, endpoints, AWS side of IAM
            - customer: client-side data encryption + integrity, network traffic protection, firewall config, customer side of IAM
        - abstract service model 
            - AWS: all of above, plus network traffic protection + SSE
            - customer: customer data + client-side encryption + data integrity
## Security Controls 
### Data at Rest and in Transit
- protecting data at rest in EMR
    - EMR: managed service by AWS, highly-scalable cluster of ec2 instances to run big data frameworks
    - does NOT encrypt data at rest by default 
    - can use DDB or S3 as persistent store 
        - can copy from there or store on local disks 
        - can use SSE-S3/KMS if using S3 
            - able to choose to encrypt data at rest, in transit, or at rest and in transit 
            - can reuse security configuration of one cluster for other clusters 
    - mechanisms to implmement protection of data at rest in local disks
        - enable local disk encryption for EBS w/n EMR 
            - LUKS: linux unified key setup
            - open-source HDFS encryption 
                - secure hadoop RPC
                - data encryption of HDFS block transfer 
- protecting data at rest in RDS
    - during creation, can enable encryption under advanced options > database options 
        - keys can be managed by KMS using AES-256
    - platform-level encryption
        - oracle and SQL server transparent data encryption (TDE): comes with a minor performance hit 
        - MySQL cryptographic functions
        - microsoft SQL - transact SQL cryptographic functions 
- protecting data at rest in S3 
    - securing the availability and reliability of data
        - by default, s3 replicates objects across ALL AZs w/n region 
        - to protect against accidental or malicious deletion, implement versioning
            - version control objects
            - recover from unintended actions
            - uses add'l S3 space + increases cost 
            - can't be turned off, only disabled after being turned on
- protecting data at rest: Glacier & DDB
    - by default, Glacier encrypts data at rest using SSE
        - each archive generates a new key and the data is encrypted using AES-256
    - data can also be encrypted before storing it on Glacier
    - DDB supports SSE using KMS and is enabled by default 
        - no option to enable or disable encryption at rest 
- protecting data in transit in RDS
    - SSL/TLS: implementation depends on DB engine
    - oracle can use NNE, which is not compatible w SSL/TLS
- protecting data in transit in EMR
    - open-source HDFS encryption: provides hadoop encryption option
    - hadoop mapreduce encrypted shuffle uses SSL/TLS
    - communications to DDB + S3 sent over HTTPS
    - connect to EMR cluster for admin purposes using SSH
- protecting data in transit: elastic beanstalk
    - HTTP over SSL/TLS (HTTPS) w signed certificates 
        - will be encrypted from client to route53 to elb, then regular http to apps
- protecting data in transit: abstract services
    - S3
        - encryption in transit managed by AWS
        - uses HTTPS and SSL/TLS connections
    - DDB
        - when accessing DDB over internet, connections should be using HTTPS to ensure data encrypted 
- protecting data in transit when using the management console
    - the console uses SSL/TLS b/w browser and AWS service endpoints in addition to using X.509 cert
    - SDKs, AWS CLI + AWS API calls not from console are RESTful APIs over HTTPS
### Network Segmentation
- network traffic protection is under customer's responsibility in container services 
- public & private subnets
    - subnets: segment VPC into different networks
    - able to refind security profile for different services in different subnets 
    - public subnets: have IGW on route to 0.0.0.0/0
- route tables
    - route b/w two or more network segments
    - define which subnets can talk to which other subnets
    - helps isolate traffic b/w subnets 
- NACLs
    - provide rule-based tool for controlling ingress and egress network traffic at protocol & subnet level
    - NACLs are attached to one or more subnets w/n VPC
    - default NACL allows traffic in and out
    - stateless; do not remember outbound connections
- security groups
    - work at instance level
    - associated w instances and provide security at protocol and port access level
    - there are no deny rules - if traffic isn't explicitly allowed, it is denied 
- NAT (network address translation)
    - allow proviate instances to have outgoing connectivity to the internet & block inbound traffic from the internet (except for response to outbound traffic)
    - resides w/n public subnet
- bastion host
    - sit w/n public SN accessed via secure connection
    - act as 'jump' server, allowing connection to private instances from internet 
    - should be locked down as much as possible 
- network security: RDS
    - RDS instances should be located w/n private subnet w/n VPC, removing exposure to the internet 
    - also helps trim down on how comprehensive a single NACL needs to be, e.g., DB SN NACL only needs to allow DB ports 
- network security: elastic beanstalk
    - can use all the above network security controls
    - beanstalk has the option to manage updates to underlying platform, OS and web and app server updates 
- network security: EMR
    - automatically uses some VPC security groups
        - during EMR job, will launch two EC2 security groups
            - SG for master node and for slaves 
        - EC2 instances used by EMR w/n cluster should be located w/n private subnet 
- network security (abstract services): DDB/S3/SQS
    - DDB: most of security, ops controls, underlying maintenance is AWS responsibility of AWS 
        - auto hardware failover
        - data replication
        - network inspections
    - S3, SQS
        - network security controls + mgmt managed by AWS
        - controlling who has access to these services is customer's responsibility via IAM
### IAM
- can configure conditional access & allowing only during set time periods or from specific IP address 
- IAM w RDS
    - any authenticated identity w appropriate perms can access RDS
    - granular perms can be granted
- IAM w EMR
    - access to clusters and to data itself managed
    - by default, EMR clusters restricted to the IAM user who created 
        - there is an option to make cluster visible to all users if required
    - can use AWS managed policies 
- S3 access controls 
    - add'l resource-based access control
        - bucket policies
        - access control
    - if there are conflicting perms b/w IAM and resource perms, least privileged access will be granted 
- IAM w DDB
    - can granted access to specific rows w/n DDB table
### Built-in Service Security Controls 
- RDS
    - offeres durability and available of data thru multi-AZ feature
        - will automatically configure a secondary DB of primary DB in different AZ 
    - automatic backups & snapshots
        - auto backups enable point-in-time recovery
        - can create snapshot of entire database (must be triggered by user)
- S3
    - MFA delete 
        - enforces add'l security measures to be used when object w/n bucket is set for deletion 

# Exam Review
- CloudTrail logs to CW logs group; remember, CW has logs group and log streams. CT needs to be able to CreateLogStream and PutLogEvents
- IAM passwords: can enforce complexity, expiry date, disable reuse, allow pw self service, and force users to contact account admin when their pw has expired 
- CW metrics: RDS sends metrics to CW every minute by default. So does SNS. EC2 + ASG are 5 minutes by default 
- CloudHSM HA group unable to communicate b/w members. Recover automatically w LunaSlotManager.reinitialize()
- Route53 and CFt have built in protection against SYN/ACK floods, UDP floods, reflection attacks and DNS query floods 
    - WAF is for apps behind R53, not for R53 itself 
- in AWS Directory Service, set up AD connector directory to existing MS AD to allow SSO for users 
- CloudTrail can be used to filter by access key to see API requests & see if any were suspicious & disable the applicable keys 
- use Trusted Advisor to determine if a security alert has been generated for lambda functions with runtime approaching depreciation 
- sharing golden images in AWS organization: enable sharing w/n org, create resource share in AWS Resource Access Manager to share images across org 
- if 2/3 CloudHSM instances go down, HSM can still maintain service 
- CFt: if logging enabled, CFt records info about each end-user request for an object & stores the files in the specified S3 bucket 
- KMS: can define data classification levels & have multiple keys per level. Recommended to use it and have at least one key per level 
- CT: logs events from all regions in account
- VPC flow logs can be configured to capture all traffic, accepted traffic only, or rejected traffic only 
- API gateway automatically protects backend from DDoS attacks, either layer 7 counterfeit requests or layer 3 SYN floods. AWS Shield Advanced can protect at layers 3, 4, 7. Route53 can protect against DNS DDoS attacks, but doesn't protect entire layers 
- to use a third-party authentication service (like Okta) with AWS, can use cognito. For MS AD, use AWS Directory Connector 
- GuardDuty is an intrusion detection service that monitors AWS account + resources for malicious activity. Can detect & can be configured to have automatic remediation
- Config is used for configuration audits of resource. Cannot automatically remediate, but can send notifications 
- HSM: public key installed on HSM appliance during provisioning 
- invalid principle in policy: not an issue with the S3 bucket arn, but relating to IAM user or the value in principle is the wrong type 
- Amazon Client VPN can allow secure login w corporate credentials to both AWS and on-prem resources
- AWS SSO secure user portal is use to manage access to multiple AWS accounts & business apps. Able to host a personalized portal to give users easy access to AWS accounts + authorized apps 
- with resource based policies, can define permissions for sub-directories of bucket separately
    - not managed policies. Read the Question!  
- WAF used to protect APIs and apps from common web exploits + bots that affect availability/security
- inspector: able to create assessment targets for different instance tags + run different rules packages in those different assessment targets 
- in CW when creating metric filters for CT logs, must create 'filter pattern' that determines what CW should monitor + extract from CT logs 
- when locking down instances, can also use linux iptables-host based restrictions on the instances to act as a firewall & another layer of security 
- when using security hub, can enable it and turn on integrations for AWS native security tools and partner integrations 
- AWS resilience hub: define, validate, track resiliency of AWS app
- AWS control tower: enforce + manage governance rules for security, ops, and compliance at scale across all orgs + accounts in AWS 
- AWS incident manager: part of SSM that enables creation of incident plans to allow for faster resolution of critical app availability + performance issues 
- when using CloudHSM HA config, failed/lost group HSM can be reinstated by hands-off (HA recovery on) or manual (HA recovery off)
- GuardDuty exfiltration finding would look something like 'Exfiltration:/IAMUSER/AnomalousBehavior' 
- if concerned about data security, can also use OS tools to encrypt file systems on EBS volumes (seems a little redundant?)
- don't be too pedantic about the questions. They're usually not trying to be *that* sneaky. if traffic is working inside the network, and there's NACLs involved, it's probably a NACL issue with outbound ports 
- cloudHSM: `aws cloudhsm describe-hsm` retrieves info about an HSM, including ENI addr + secret access key (aka public key)
- VPCs: read the question! private subnets to NAT gateways for internet comms. Public subnets to IGW, VPN traffic to VPGw
- CT log naming: acctID_CT_Region_dateTime_uniqueString.FileNameFormat 
- can tag findings in inspector with key-value attribute to each finding according to customer policy (in addition to inspector findings severity)
- instance store data remains when instance reboots. Stopping, terminating, or underlying hardware failure causes loss of data in instance store volume 
- can use config to enforce proper AMIs are used 
- safest process to delete existing KMS keys is to use the full 30-day waiting period before deletion
- KMS keys can operate in multi-region scope, but AWS recommends region-specific keys for most cases 
- AWS inspector is used to check network accessibility and security vulnerability of EC2 instances, container images, and security state of apps running on those resources
    - can have it scan ECR & review findings for container images w vulnerable OS packages 
- CW events rules can trigger based on CT calls, even if the question words it as just 'AWS API calls' & can quickly submit events into Kinesis Streams
- can use trusted advisor to determine if security alert has been generated for origin servers that have SSL certs that are expired, about to expire, missing, or that use outdataed encryption
- CloudWatch Events do things in response to APIs; alerts for CT services are set up and triggered through CW 
- can create IAM credential report as often as every 4 hours. If new report requested, if none are newer than 4 hours, a new one is automatically generated 
- REMEMBER TO READ & UNDERSTAND THE QUESTIONS